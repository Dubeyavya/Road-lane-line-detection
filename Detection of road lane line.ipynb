{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a7492d",
   "metadata": {},
   "source": [
    "Detection Of Road Lane Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a2f379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.7.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: moviepy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (2.26.0)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib numpy opencv-python moviepy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d15b5",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90a5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d1002",
   "metadata": {},
   "source": [
    "Apply frame masking and find region of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e77a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interested_region(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    return cv2.bitwise_and(img, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee07f9",
   "metadata": {},
   "source": [
    "Conversion of pixels to a line in Hough Transform space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d36175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(line_img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05730e9f",
   "metadata": {},
   "source": [
    "Create two lines in each frame after Hough transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51045b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_drawn(img, lines, color=[255, 0, 0], thickness=6):\n",
    "    global cache\n",
    "    global first_frame\n",
    "    slope_l, slope_r = [],[]\n",
    "    lane_l,lane_r = [],[]\n",
    "\n",
    "    α = 0.2\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            if slope > 0.4:\n",
    "                slope_r.append(slope)\n",
    "                lane_r.append(line)\n",
    "            elif slope < -0.4:\n",
    "                slope_l.append(slope)\n",
    "                lane_l.append(line)\n",
    "            img.shape[0] = min(y1, y2, img.shape[0])\n",
    "\n",
    "    if ((len(lane_l) == 0) or (len(lane_r) == 0)):\n",
    "        print('no lane detected')\n",
    "        return 1\n",
    "\n",
    "    slope_mean_l = np.mean(slope_l, axis=0)\n",
    "    slope_mean_r = np.mean(slope_r, axis=0)\n",
    "    mean_l = np.mean(np.array(lane_l), axis=0)\n",
    "    mean_r = np.mean(np.array(lane_r), axis=0)\n",
    "\n",
    "    if ((slope_mean_r == 0) or (slope_mean_l == 0)):\n",
    "        print('dividing by zero')\n",
    "        return 1\n",
    "\n",
    "    x1_l = int((img.shape[0] - mean_l[0][1] - (slope_mean_l * mean_l[0][0])) / slope_mean_l)\n",
    "    x2_l = int((img.shape[0] - mean_l[0][1] - (slope_mean_l * mean_l[0][0])) / slope_mean_l)\n",
    "    x1_r = int((img.shape[0] - mean_r[0][1] - (slope_mean_r * mean_r[0][0])) / slope_mean_r)\n",
    "    x2_r = int((img.shape[0] - mean_r[0][1] - (slope_mean_r * mean_r[0][0])) / slope_mean_r)\n",
    "\n",
    "    if x1_l > x1_r:\n",
    "        x1_l = int((x1_l + x1_r) / 2)\n",
    "        x1_r = x1_l\n",
    "        y1_l = int((slope_mean_l * x1_l) + mean_l[0][1] - (slope_mean_l * mean_l[0][0]))\n",
    "        y1_r = int((slope_mean_r * x1_r) + mean_r[0][1] - (slope_mean_r * mean_r[0][0]))\n",
    "        y2_l = int((slope_mean_l * x2_l) + mean_l[0][1] - (slope_mean_l * mean_l[0][0]))\n",
    "        y2_r = int((slope_mean_r * x2_r) + mean_r[0][1] - (slope_mean_r * mean_r[0][0]))\n",
    "    else:\n",
    "        y1_l = img.shape[0]\n",
    "        y2_l = img.shape[0]\n",
    "        y1_r = img.shape[0]\n",
    "        y2_r = img.shape[0]\n",
    "\n",
    "    present_frame = np.array([x1_l, y1_l, x2_l, y2_l, x1_r, y1_r, x2_r, y2_r], dtype=\"float32\")\n",
    "\n",
    "    if first_frame == 1:\n",
    "        next_frame = present_frame\n",
    "        first_frame = 0\n",
    "    else:\n",
    "        prev_frame = cache\n",
    "        next_frame = (1 - α) * prev_frame + α * present_frame\n",
    "\n",
    "    cv2.line(img, (int(next_frame[0]), int(next_frame[1])), (int(next_frame[2]), int(next_frame[3])), color, thickness)\n",
    "    cv2.line(img, (int(next_frame[4]), int(next_frame[5])), (int(next_frame[6]), int(next_frame[7])), color, thickness)\n",
    "\n",
    "    cache = next_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b387b",
   "metadata": {},
   "source": [
    "Process each frame of video to detect lane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a14bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "\n",
    "    global first_frame\n",
    "\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "\n",
    "    lower_yellow = np.array([20, 100, 100], dtype = \"uint8\")\n",
    "    upper_yellow = np.array([30, 255, 255], dtype=\"uint8\")\n",
    "\n",
    "    mask_yellow = cv2.inRange(img_hsv, lower_yellow, upper_yellow)\n",
    "    mask_white = cv2.inRange(gray_image, 200, 255)\n",
    "    mask_yw = cv2.bitwise_or(mask_white, mask_yellow)\n",
    "    mask_yw_image = cv2.bitwise_and(gray_image, mask_yw)\n",
    "\n",
    "    gauss_gray= cv2.GaussianBlur(mask_yw_image, (5, 5), 0)\n",
    "\n",
    "    canny_edges=cv2.Canny(gauss_gray, 50, 150)\n",
    "\n",
    "    imshape = image.shape\n",
    "    lower_left = [imshape[1]/9,imshape[0]]\n",
    "    lower_right = [imshape[1]-imshape[1]/9,imshape[0]]\n",
    "    top_left = [imshape[1]/2-imshape[1]/8,imshape[0]/2+imshape[0]/10]\n",
    "    top_right = [imshape[1]/2+imshape[1]/8,imshape[0]/2+imshape[0]/10]\n",
    "    vertices = [np.array([lower_left,top_left,top_right,lower_right],dtype=np.int32)]\n",
    "    roi_image = interested_region(canny_edges, vertices)\n",
    "\n",
    "    theta = np.pi/180\n",
    "\n",
    "    line_image = hough_lines(roi_image, 4, theta, 30, 100, 180)\n",
    "    result = weighted_img(line_image, image, α=0.8, β=1., λ=0.)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c71595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\HP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe3dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "260a1310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Path to Input Video File: C:\\Users\\HP\\Downloads\\lane detection test.mp4\n"
     ]
    }
   ],
   "source": [
    "input_filename = 'C:\\\\Users\\\\HP\\\\Downloads\\\\lane detection test.mp4'\n",
    "input_file_path = os.path.join(current_directory, input_filename)\n",
    "print(\"Full Path to Input Video File:\", input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf2f582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\HP\\path/to/your/output/video/' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Specify the directory path relative to the current working directory\n",
    "directory_path = os.path.join(current_directory, 'path/to/your/output/video/')\n",
    "\n",
    "# Create the directory\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "\n",
    "print(f\"Directory '{directory_path}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f551fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video C:\\Users\\HP\\path\\to\\your\\output\\video\\output_video.mp4.\n",
      "Moviepy - Writing video C:\\Users\\HP\\path\\to\\your\\output\\video\\output_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\HP\\path\\to\\your\\output\\video\\output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "first_frame = 1\n",
    "white_output = r'C:\\Users\\HP\\path\\to\\your\\output\\video\\output_video.mp4'\n",
    "\n",
    "input_file_path = os.path.join(current_directory, 'C:\\\\Users\\\\HP\\\\Downloads\\\\lane detection test.mp4')\n",
    "clip1 = VideoFileClip(input_file_path)\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee5c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading frame from camera1\n",
      "Error reading frame from camera2\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "global last_frame1                                   \n",
    "last_frame1 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global last_frame2                                      \n",
    "last_frame2 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global cap1\n",
    "global cap2\n",
    "\n",
    "# Update the video file paths\n",
    "cap1 = cv2.VideoCapture(\"C:\\\\Users\\\\HP\\\\Downloads\\\\lane detection test.mp4\")\n",
    "cap2 = cv2.VideoCapture(r'C:\\Users\\HP\\path\\to\\your\\output\\video\\output_video.mp4')\n",
    "\n",
    "def show_vid():                                       \n",
    "    if not cap1.isOpened():                             \n",
    "        print(\"Can't open the camera1\")\n",
    "        return\n",
    "    flag1, frame1 = cap1.read()\n",
    "    if not flag1:\n",
    "        print(\"Error reading frame from camera1\")\n",
    "        return\n",
    "    frame1 = cv2.resize(frame1, (400, 500))\n",
    "    global last_frame1\n",
    "    last_frame1 = frame1.copy()\n",
    "    pic = cv2.cvtColor(last_frame1, cv2.COLOR_BGR2RGB)     \n",
    "    img = Image.fromarray(pic)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    lmain.imgtk = imgtk\n",
    "    lmain.configure(image=imgtk)\n",
    "    lmain.after(10, show_vid)\n",
    "\n",
    "def show_vid2():\n",
    "    if not cap2.isOpened():                             \n",
    "        print(\"Can't open the camera2\")\n",
    "        return\n",
    "    flag2, frame2 = cap2.read()\n",
    "    if not flag2:\n",
    "        print(\"Error reading frame from camera2\")\n",
    "        return\n",
    "    frame2 = cv2.resize(frame2, (400, 500))\n",
    "    global last_frame2\n",
    "    last_frame2 = frame2.copy()\n",
    "    pic2 = cv2.cvtColor(last_frame2, cv2.COLOR_BGR2RGB)\n",
    "    img2 = Image.fromarray(pic2)\n",
    "    img2tk = ImageTk.PhotoImage(image=img2)\n",
    "    lmain2.img2tk = img2tk\n",
    "    lmain2.configure(image=img2tk)\n",
    "    lmain2.after(10, show_vid2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()                                     \n",
    "    lmain = tk.Label(master=root)\n",
    "    lmain2 = tk.Label(master=root)\n",
    "\n",
    "    lmain.pack(side=LEFT)\n",
    "    lmain2.pack(side=RIGHT)\n",
    "    root.title(\"Lane-line detection\")            \n",
    "    root.geometry(\"900x700+100+10\") \n",
    "    exitbutton = Button(root, text='Quit', fg=\"red\", command=root.destroy)\n",
    "    exitbutton.pack(side=BOTTOM)\n",
    "    show_vid()\n",
    "    show_vid2()\n",
    "    root.mainloop()\n",
    "\n",
    "    # Release the video captures when the GUI is closed\n",
    "    cap1.release()\n",
    "    cap2.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
